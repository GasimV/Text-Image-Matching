{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj54_x2eJVuF",
        "outputId": "45750a38-3782-442f-98fe-6b8e3900c68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "metadata": {
        "id": "q5gA_kgoeIk3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjJTF1SVKLFD",
        "outputId": "a8293658-67e4-49aa-a303-150205f34188"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the expert and crowd annotations data\n",
        "expert_annotations_path = '/content/drive/My Drive/ExpertAnnotations.tsv'\n",
        "crowd_annotations_path = '/content/drive/My Drive/CrowdAnnotations.tsv'\n",
        "\n",
        "# Read the data\n",
        "expert_data = pd.read_csv(expert_annotations_path, sep='\\t', header=None)\n",
        "crowd_data = pd.read_csv(crowd_annotations_path, sep='\\t', header=None)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(expert_data.head())\n",
        "print()\n",
        "print(crowd_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6nUaUhbJ79Y",
        "outputId": "f95e7d27-19a4-46f9-ffc1-a0e819c03f3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           0                            1  2  3  4\n",
            "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  1  1  1\n",
            "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  1  1  2\n",
            "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  1  1  2\n",
            "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  1  2  2\n",
            "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  1  1  2\n",
            "\n",
            "                           0                            1    2  3  4\n",
            "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2  1.0  3  0\n",
            "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2  0.0  0  3\n",
            "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2  0.0  0  3\n",
            "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2  0.0  0  3\n",
            "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2  0.0  0  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наборы данных успешно загружены. Вот краткий обзор данных:\n",
        "\n",
        "**Данные экспертных аннотаций**\n",
        "\n",
        "  - Данные имеют пять столбцов:\n",
        "         0: Имя файла изображения.\n",
        "         1: Идентификатор описания.\n",
        "         2, 3, 4: Рейтинги экспертов, каждый столбец соответствует рейтингу эксперта по шкале от 1 до 4.\n",
        "\n",
        "**Данные аннотаций краудсорса**\n",
        "\n",
        "  - Данные также состоят из пяти столбцов:\n",
        "         0: Имя файла изображения.\n",
        "         1: Идентификатор описания.\n",
        "         2: Процент исполнителей, подтвердивших соответствие текста картинке.\n",
        "         3: Количество исполнителей, подтвердивших соответствие текста картинке.\n",
        "         4: Количество исполнителей, подтвердивших несоответствие текста картинке.\n",
        "\n",
        "Следующие шаги будут включать в себя:\n",
        "\n",
        "  - Агрегирование оценок экспертов в одно значение для каждой пары изображение-текст.\n",
        "  - Расчет оценки соответствия краудсорсинговых рейтингов.\n",
        "  - Объединение обоих для создания единой меры вероятности, представляющей вероятность совпадения текста с изображением.\n",
        "\n",
        "Реализуем эти шаги, чтобы подготовить данные для дальнейшего использования в модели."
      ],
      "metadata": {
        "id": "eEry2-fDNAaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to aggregate expert ratings\n",
        "def aggregate_expert_ratings(ratings):\n",
        "    mode_rating = ratings.mode()\n",
        "    if len(mode_rating) == 1:\n",
        "        # Return the mode if a clear majority exists\n",
        "        return mode_rating.iloc[0]\n",
        "    else:\n",
        "        # Return NaN if no consensus (all different ratings)\n",
        "        return np.nan\n",
        "\n",
        "# Aggregating expert ratings\n",
        "expert_data['aggregated_rating'] = expert_data[[2, 3, 4]].apply(aggregate_expert_ratings, axis=1)\n",
        "\n",
        "# Calculating consistency score for crowd data\n",
        "# Using the percentage of performers who confirmed the match as the consistency score\n",
        "crowd_data['consistency_score'] = crowd_data[2]\n",
        "\n",
        "# Dropping rows with no consensus in expert ratings\n",
        "expert_data.dropna(subset=['aggregated_rating'], inplace=True)\n",
        "\n",
        "# Displaying the first few rows of the transformed datasets\n",
        "expert_data.head(), crowd_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imiHI1yVKo2R",
        "outputId": "b199993b-1fb0-4e36-8057-dcffa01c233d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                           0                            1  2  3  4  \\\n",
              " 0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  1  1  1   \n",
              " 1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  1  1  2   \n",
              " 2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  1  1  2   \n",
              " 3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  1  2  2   \n",
              " 4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  1  1  2   \n",
              " \n",
              "    aggregated_rating  \n",
              " 0                1.0  \n",
              " 1                1.0  \n",
              " 2                1.0  \n",
              " 3                2.0  \n",
              " 4                1.0  ,\n",
              "                            0                            1    2  3  4  \\\n",
              " 0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2  1.0  3  0   \n",
              " 1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2  0.0  0  3   \n",
              " 2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2  0.0  0  3   \n",
              " 3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2  0.0  0  3   \n",
              " 4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2  0.0  0  3   \n",
              " \n",
              "    consistency_score  \n",
              " 0                1.0  \n",
              " 1                0.0  \n",
              " 2                0.0  \n",
              " 3                0.0  \n",
              " 4                0.0  )"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Экспертные и краудсорсинговые данные аннотаций были успешно преобразованы:\n",
        "\n",
        "**Преобразование данных экспертных аннотаций**:\n",
        "\n",
        "  - ***Совокупный рейтинг***: большинство голосов было применено для создания единого совокупного рейтинга для каждой пары изображение-текст. В тех случаях, когда консенсус не был найден (все разные рейтинги), эти записи исключались.\n",
        "\n",
        "**Преобразование данных краудсорс аннотаций**:\n",
        "\n",
        "  - ***Оценки соответствия***: процент исполнителей, подтвердивших, что текст соответствует изображению, использовался непосредственно в качестве оценки соответствия.\n",
        "\n",
        "Благодаря этим преобразованиям оба набора данных теперь предоставляют более упрощенную и полезную меру для понимания согласованности текста и изображения. Следующие шаги будут включать нормализацию этих оценок и их объединение для формирования единого набора данных с целевой вероятностью от 0 до 1 для обучения модели."
      ],
      "metadata": {
        "id": "rY09AgJISXc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Expert Aggregated Rating to a scale of 0-1\n",
        "expert_data['normalized_rating'] = expert_data['aggregated_rating'] / 4  # as the rating scale is 1 to 4\n",
        "\n",
        "# Combining the scores\n",
        "# A simple method to combine the scores is to take a weighted average of the expert and crowd scores.\n",
        "# As suggested, using 0.6 for expert and 0.4 for crowd scores.\n",
        "combined_score = (\n",
        "    0.6 * expert_data['normalized_rating'] + 0.4 * crowd_data['consistency_score']\n",
        ")\n",
        "\n",
        "# Creating a combined DataFrame\n",
        "combined_data = pd.DataFrame({\n",
        "    'ImageID': expert_data[0],\n",
        "    'DescriptionID': expert_data[1],\n",
        "    'ExpertRating': expert_data['normalized_rating'],\n",
        "    'CrowdConsistency': crowd_data['consistency_score'],\n",
        "    'CombinedScore': combined_score\n",
        "})\n",
        "\n",
        "# Displaying the first few rows of the combined data\n",
        "combined_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fXJtYPu1Ko4y",
        "outputId": "9dbe6e6f-8f47-4fa4-bd98-99896b93e685"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     ImageID                DescriptionID  ExpertRating  \\\n",
              "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2          0.25   \n",
              "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2          0.25   \n",
              "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2          0.25   \n",
              "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2          0.50   \n",
              "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2          0.25   \n",
              "\n",
              "   CrowdConsistency  CombinedScore  \n",
              "0               1.0           0.55  \n",
              "1               0.0           0.15  \n",
              "2               0.0           0.15  \n",
              "3               0.0           0.30  \n",
              "4               0.0           0.15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f900e61-4b74-4f0c-8a28-59dab37a76f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageID</th>\n",
              "      <th>DescriptionID</th>\n",
              "      <th>ExpertRating</th>\n",
              "      <th>CrowdConsistency</th>\n",
              "      <th>CombinedScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1056338697_4f7d7ce270.jpg</td>\n",
              "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1056338697_4f7d7ce270.jpg</td>\n",
              "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1056338697_4f7d7ce270.jpg</td>\n",
              "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1056338697_4f7d7ce270.jpg</td>\n",
              "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1056338697_4f7d7ce270.jpg</td>\n",
              "      <td>3286822339_5535af6b93.jpg#2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f900e61-4b74-4f0c-8a28-59dab37a76f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f900e61-4b74-4f0c-8a28-59dab37a76f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f900e61-4b74-4f0c-8a28-59dab37a76f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b53f1563-d6f5-4728-b6a3-dbe7dd02f092\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b53f1563-d6f5-4728-b6a3-dbe7dd02f092')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b53f1563-d6f5-4728-b6a3-dbe7dd02f092 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Завершены нормализация и объединение экспертных и краудсорсинговых оценок. Вот сводка объединенных данных:\n",
        "\n",
        "- ***ImageID***: идентификатор изображения.\n",
        "- ***DescriptionID***: идентификатор конкретного описания, связанного с изображением.\n",
        "- ***ExpertRating***: нормализованный рейтинг экспертов по шкале от 0 до 1.\n",
        "- ***CrowdConsistency***: оценка соответствия краудсорсинговых данных.\n",
        "- ***CombinedScore***: средневзвешенное значение ExpertRating и CrowdConsistency с весами 0,6 и 0,4 соответственно.\n",
        "\n",
        "Комбинированный балл теперь предоставляет единую меру по шкале от 0 до 1, представляющую вероятность того, что изображение соответствует текстовому описанию. Эту оценку можно использовать в качестве целевой переменной для обучения модели, прогнозирующей согласованность текста и изображения."
      ],
      "metadata": {
        "id": "21VJihg3SbRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка данных"
      ],
      "metadata": {
        "id": "jDjvbg53hTvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/drive/My Drive/train_dataset.csv'\n",
        "train_dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset and its basic info\n",
        "print(train_dataset.info())\n",
        "print()\n",
        "print(train_dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaQxN_CuKo7Z",
        "outputId": "95c8609f-1004-4d47-dcf1-f9146434f03a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5822 entries, 0 to 5821\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   image       5822 non-null   object\n",
            " 1   query_id    5822 non-null   object\n",
            " 2   query_text  5822 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 136.6+ KB\n",
            "None\n",
            "\n",
            "                       image                     query_id  \\\n",
            "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
            "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
            "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
            "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
            "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
            "\n",
            "                                          query_text  \n",
            "0  A young child is wearing blue goggles and sitt...  \n",
            "1  A young child is wearing blue goggles and sitt...  \n",
            "2  A young child is wearing blue goggles and sitt...  \n",
            "3  A young child is wearing blue goggles and sitt...  \n",
            "4  A young child is wearing blue goggles and sitt...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Файл train_dataset.csv содержит 5822 записи и состоит из трех столбцов:\n",
        "\n",
        "- **image**: этот столбец содержит имена файлов изображений.\n",
        "- **query_id**: этот столбец имеет уникальный идентификатор для каждого описания в формате <имя файла изображения>#<порядковый номер описания>.\n",
        "- **query_text**: этот столбец содержит текстовое описание, связанное с каждым изображением.\n",
        "\n",
        "Из первых нескольких строк очевидно, что несколько строк могут относиться к одному и тому же изображению, но с разными описаниями, или одно и то же описание может повторяться на разных изображениях.\n",
        "\n",
        "Учитывая поставленную задачу, значительная часть очистки данных будет включать проверку столбца query_text на предмет любых признаков ограниченного контента, особенно описаний с участием детей до 16 лет. Нам нужно будет составить список ключевых слов, которые, вероятно, являются индикаторами такого контента, и отфильтровать все строки, соответствующие этим критериям.\n",
        "\n",
        "Давайте предположим, что это упрощенный список ключевых слов, которые могут быть связаны с детьми. В реальном сценарии нам нужен более полный и конфиденциальный список, возможно, проверенный командой юристов.\n",
        "\n",
        "Примеры ключевых слов: [\"child\", \"children\", \"kid\", \"boy\", \"girl\", \"school\", \"playground\"]\n",
        "\n",
        "Затем мы отфильтруем описания с помощью ключевых слов. Мы пройдемся по столбцу query_text и удалим все строки, содержащие эти ключевые слова. Этот процесс можно усовершенствовать с помощью регулярного выражения для более детального сопоставления."
      ],
      "metadata": {
        "id": "Lm21tqBYh_FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define a simple keyword list for demonstration purposes\n",
        "keywords = [\"child\", \"children\", \"kid\", \"boy\", \"girl\", \"school\", \"playground\"]\n",
        "\n",
        "# Step 2: Filter out descriptions containing these keywords\n",
        "# Convert query_text to lower case and then check if any of the keywords are in the query_text\n",
        "filtered_dataset = train_dataset[~train_dataset['query_text'].str.lower().str.contains('|'.join(keywords))]\n",
        "\n",
        "# Show the effect of filtering\n",
        "original_count = train_dataset.shape[0]\n",
        "filtered_count = filtered_dataset.shape[0]\n",
        "\n",
        "original_count, filtered_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk2PtLEpKo-C",
        "outputId": "35c2dd1f-630b-464c-d5df-3a02a4b77863"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5822, 4321)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Процесс фильтрации на основе ключевых слов сократил набор данных с 5822 записей до 4321 записи. Это означает, что 1501 запись была удалена, поскольку они, вероятно, содержали ссылки на детей или связанные контексты.\n",
        "\n",
        "Это базовый подход и, вероятно, не исчерпывающий. Он служит отправной точкой, и в реальном приложении потребуется более детальный и всеобъемлющий процесс фильтрации, возможно, с использованием более сложных методов обработки естественного языка и более тщательного списка ключевых слов."
      ],
      "metadata": {
        "id": "Sq4VvBqajq5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Векторизация изображений"
      ],
      "metadata": {
        "id": "0k5PKo0qhkFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the pre-trained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "\n",
        "# Check if GPU is available and move the model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Function to load an image, transform it, and extract features using GPU\n",
        "def vectorize_image(image_path, model, transform, device):\n",
        "    # Load and transform the image\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "    # Move image to the device (GPU if available)\n",
        "    image = image.to(device)\n",
        "\n",
        "    # Extract features\n",
        "    with torch.no_grad():  # No need to track gradients for feature extraction\n",
        "        features = model(image)\n",
        "\n",
        "    # Convert features to a vector\n",
        "    return features.squeeze().cpu().detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrRSE-0MaoMj",
        "outputId": "e8512dd5-6c64-4206-c45f-e89f2a0f779e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_images_in_folder(folder_path, model, transform, device):\n",
        "    import os\n",
        "\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "    vectorized_images = []\n",
        "\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        # Pass the 'device' argument to the vectorize_image function\n",
        "        vectorized_image = vectorize_image(file_path, model, transform, device)\n",
        "        vectorized_images.append((file, vectorized_image))\n",
        "\n",
        "    return vectorized_images\n",
        "\n",
        "# Make sure to define the device somewhere in your script:\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Path to your train_images folder in Google Drive\n",
        "folder_path = '/content/drive/My Drive/train_images'\n",
        "\n",
        "# Vectorize all images in the folder, don't forget to pass the 'device'\n",
        "vectorized_images = vectorize_images_in_folder(folder_path, model, transform, device)"
      ],
      "metadata": {
        "id": "musA7bDQKpC-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы векторизовать изображения с помощью сверточной нейронной сети, такой как ResNet-18, были выполнены следующие шаги:\n",
        "\n",
        "1. ***Загружена предварительно обученная модель***: ResNet-18, предварительно обученную на большом наборе данных ImageNet.\n",
        "2. ***Удалены полно-связные слои***: Эти слои обычно находятся в конце сети и предназначены для исходной задачи обучения (например, классификации классов ImageNet). Удалив или пропустив эти слои, мы получаем признаки изображения вместо прогноза класса.\n",
        "3. ***Обработаны изображения***: Изображения стандартизированы до входного размера, ожидаемого моделью, путем изменения их размера и нормализации.\n",
        "4. ***Извлечены признаки***: изображения были переданы нейронной сети, чтобы получить векторизованное представление."
      ],
      "metadata": {
        "id": "i-BBers1kd1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Векторизация текстов"
      ],
      "metadata": {
        "id": "0hTLgqcehupx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test_queries.csv file\n",
        "test_queries_path = '/content/drive/My Drive/test_queries.csv'\n",
        "\n",
        "# Load the dataset with a specified separator and handling bad lines\n",
        "try:\n",
        "    test_queries = pd.read_csv(test_queries_path, sep=\"|\", on_bad_lines='skip')\n",
        "    loaded_successfully = True\n",
        "except Exception as e:\n",
        "    loaded_successfully = False\n",
        "    error_message = str(e)\n",
        "\n",
        "# Display the outcome\n",
        "if loaded_successfully:\n",
        "    print(\"Data loaded successfully.\")\n",
        "    print(test_queries.head())\n",
        "else:\n",
        "    print(\"Failed to load data:\", error_message)\n",
        "\n",
        "test_queries.drop[\"Unnamed\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR_GAiAXeulx",
        "outputId": "af792877-e00b-41e0-912b-2cc203fb13da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "   Unnamed: 0                     query_id  \\\n",
            "0           0  1177994172_10d143cb8d.jpg#0   \n",
            "1           1  1177994172_10d143cb8d.jpg#1   \n",
            "2           2  1177994172_10d143cb8d.jpg#2   \n",
            "3           3  1177994172_10d143cb8d.jpg#3   \n",
            "4           4  1177994172_10d143cb8d.jpg#4   \n",
            "\n",
            "                                          query_text  \\\n",
            "0  Two blonde boys , one in a camouflage shirt an...   \n",
            "1  Two boys are squirting water guns at each other .   \n",
            "2            Two boys spraying each other with water   \n",
            "3  Two children wearing jeans squirt water at eac...   \n",
            "4  Two young boys are squirting water at each oth...   \n",
            "\n",
            "                       image  \n",
            "0  1177994172_10d143cb8d.jpg  \n",
            "1  1177994172_10d143cb8d.jpg  \n",
            "2  1177994172_10d143cb8d.jpg  \n",
            "3  1177994172_10d143cb8d.jpg  \n",
            "4  1177994172_10d143cb8d.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В процессе загрузки данных было обнаружено, что CSV-файл не имеет ожидаемой структуры, в результате чего один столбец со всеми данными и некоторые строки не совпадают с ожидаемыми полями. Первая строка объединила несколько полей в одну строку, разделенную знаком «|».\n",
        "\n",
        "Чтобы решить эту проблему, я указал разделитель знаком \"|\" и данные были успешно загружены. DataFrame \"test_queries\" теперь правильно отображает отдельные столбцы для query_id, query_text и изображения. Также, в датафрейме был еще один безымянный столбец, вероятно, из индекса или дополнительного разделителя в файле, поэтому он был удален.\n",
        "\n",
        "Теперь, когда данные структурированы правильно, мы можем приступить к векторизации текста с помощью BERT для генерации эмбеддингов."
      ],
      "metadata": {
        "id": "rtBbl1AWp4wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available and set it as the device, otherwise use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "def vectorize_text(texts, tokenizer, model, device):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens = True,\n",
        "                            max_length = 64,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,\n",
        "                            return_tensors = 'pt',\n",
        "                       )\n",
        "\n",
        "        # Move the tensors to the same device as the model\n",
        "        input_ids.append(encoded_dict['input_ids'].to(device))\n",
        "        attention_masks.append(encoded_dict['attention_mask'].to(device))\n",
        "\n",
        "    # Concatenate the list of tensors into a single tensor\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "        # Retrieve the last hidden states\n",
        "        last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        # Move the embeddings back to the CPU for further processing or storage\n",
        "        last_hidden_states = last_hidden_states.cpu()\n",
        "\n",
        "    return last_hidden_states\n",
        "\n",
        "# Get the embeddings for the query_text\n",
        "texts = test_queries['query_text'].tolist()  # Convert the text column to a list\n",
        "embeddings = vectorize_text(texts, tokenizer, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkdmqi2Te4Tm",
        "outputId": "73157295-068c-4187-b321-e0b404cc3681"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы векторизировать тексты с помощью BERT из Hugging Face Transformers, были выполнены следующие действия:\n",
        "\n",
        "1. **Настройка среды**: установлена необходимая библиотека из Hugging Face - transformers.\n",
        "2. **Загрузка предварительно обученной модели BERT и токенизатора**: Использована предварительно обученная модель BERT, подходящая для наших нужд, вместе с соответствующим токенизатором.\n",
        "3. **Предварительная обработка и токенизация текста**: Подготовлены текстовые данные для модели, включая их токенизацию и правильное форматирование.\n",
        "4. **Генерация эмбеддингов**: токенизированный текст был передан модели, чтобы получить эмбеддинги - числовые векторы."
      ],
      "metadata": {
        "id": "D9bNaO6Cm4gC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o53GIl8sgu3k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8Lmt2r6hC0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}